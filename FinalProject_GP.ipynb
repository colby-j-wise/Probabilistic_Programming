{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import edward as ed\n",
    "from edward.models import Normal\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# our functions\n",
    "import setup\n",
    "import data\n",
    "import visualizations\n",
    "import basis_functions\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "setup.set_random_seeds(42)\n",
    "plt.style.use(\"seaborn-talk\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manhattan = data.get_borough_data(\"data/preprocessed.csv\", \"Manhattan\")\n",
    "ues_to_msh = data.get_neighborhood_to_neighborhood(\"Morningside Heights\", \"Upper East Side-Carnegie Hill\", manhattan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indicator_cols = [\"pickup_latitude\", \"pickup_longitude\", \"dropoff_latitude\", \"dropoff_longitude\", \"manhattan_distance\", \"pickup_hour\", \"pickup_timestamp\"]\n",
    "y_cols = [\"trip_duration\"]\n",
    "\n",
    "x_train_raw, y_train_raw, x_test_raw, y_test_raw = data.train_test_split(ues_to_msh, 0.1, indicator_cols, y_cols)\n",
    "x_train = data.standardize_cols(x_train_raw)\n",
    "x_test = data.standardize_cols(x_test_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box's Loop - Iteration 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Gaussian Process\n",
    "\n",
    "Gaussian processes (GPs) are a supervised machine learning algorithm that measures the similarity between input data points, using a predefined kernel function, to predict the value of an unseen data point. We like to think about GPs as: defining an infinite distribution on functions over a continuous sapce where we observe some data points and want to assign probabilities to all the ways a line could be drawn through those points. The idea is that we hope these lines (or functions) we draw are similar with high probability to that true function which we will never know. \n",
    "\n",
    "Drawing a parallel to our polynomial basis GLM example: instead of choosing a polynomial basis function of degree four, with GPs using a kernel function we'd like to infer the true function from our data. Hence, GPs allow us retain the flexibility of capturing non-linearities in our data but accounting for \"infinite\" numbers of basis functions. \n",
    "\n",
    "### Interpretation of Kernel Function\n",
    "\n",
    "GPs are parameterized by a pre-determined *kernel function* which is positive-semidefinite covariance matrix that calculated distanced between every pair of $N$ observed points. The Kernel function must be a square matrix and allows use to explore *smoothness* and *periodicity* in our observed data. \n",
    "\n",
    "In our analysis we will explore a few kernel functions but note there are many popular kernel functions, some more applicable than others and exploring them all was impossible. \n",
    "\n",
    "### Model Overview\n",
    "\n",
    "A GP can be specified entirely by it's Kernel Function and mean (often assumed to 0): \n",
    "\n",
    "Where,\n",
    "\n",
    "**Prior:** $p(f) = GP(\\ 0,\\ K(x,x',\\theta)\\ )$ where $\\theta$ = *length_scale* $l_f$, sigma $\\sigma_f$\n",
    "\n",
    "**Likelihood:**  $p(y\\ |\\ f,\\ X,\\ \\theta) = GP(\\ f,\\ K(x,x', \\theta)\\ )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected.shape (70,)\n",
      "prediction\n",
      "[ 11.34889621  18.54625534  35.93692691  25.19478301  10.20763848\n",
      "  21.62984954  16.90604639  34.07454377   7.83611066  19.95123486\n",
      "   9.29506565  13.27852904   9.21523767  11.10381997   4.96393114\n",
      "  24.74958625  10.96811069  20.2788163   13.1529822   15.61556318\n",
      "  22.19526823  17.21266034  10.09846134  13.09524108  15.74238393\n",
      "   9.95723267  15.16143206  15.44127301  28.45845798  19.06734572\n",
      "  12.40959524  19.36835764  28.54778205   4.70653486   7.66773061\n",
      "   4.93242844  12.94008577  12.54136809  12.3250377   11.55846327\n",
      "   2.30321391  16.60690634  20.80901859  13.74256706  21.74172237\n",
      "   9.42484636   9.82305667  21.17685515  11.89634161   7.77866968\n",
      "  -0.50854894   9.70219824  12.65670345  10.71287245   8.78996084\n",
      "  10.58268715  20.51633212  10.55296479  22.16884611   4.43730056\n",
      "  10.33461223  11.85048421  16.07845154  18.23911833  19.89156371\n",
      "  15.5184552   29.3720064   19.88120754   9.20595701  15.00647261]\n",
      "actual\n",
      "     trip_duration\n",
      "495      14.466667\n",
      "164      15.050000\n",
      "54       22.800000\n",
      "582      17.366667\n",
      "608       6.933333\n",
      "367      16.500000\n",
      "371      16.500000\n",
      "670      28.433333\n",
      "583       8.833333\n",
      "310      15.033333\n",
      "355      29.983333\n",
      "604       9.466667\n",
      "521       9.783333\n",
      "558      11.700000\n",
      "132       6.633333\n",
      "292      14.533333\n",
      "131      10.933333\n",
      "81       10.616667\n",
      "86       25.816667\n",
      "652      26.000000\n",
      "453      24.100000\n",
      "624      27.533333\n",
      "447      11.483333\n",
      "519      15.750000\n",
      "396      12.416667\n",
      "644      10.033333\n",
      "77       10.033333\n",
      "477      12.800000\n",
      "275      30.716667\n",
      "665      23.183333\n",
      "..             ...\n",
      "634       7.383333\n",
      "311      16.033333\n",
      "430      19.666667\n",
      "658      18.333333\n",
      "78       21.933333\n",
      "650      12.600000\n",
      "514      11.850000\n",
      "328      17.250000\n",
      "581      12.233333\n",
      "653       8.300000\n",
      "535      12.666667\n",
      "599      15.366667\n",
      "284      23.316667\n",
      "360      10.266667\n",
      "439      10.783333\n",
      "259      12.933333\n",
      "493      16.400000\n",
      "215      12.550000\n",
      "158      25.866667\n",
      "10        9.250000\n",
      "63       10.950000\n",
      "354      19.650000\n",
      "552      10.350000\n",
      "181      15.366667\n",
      "260      18.083333\n",
      "109      11.800000\n",
      "327       9.550000\n",
      "31       10.516667\n",
      "690       5.133333\n",
      "642      16.700000\n",
      "\n",
      "[70 rows x 1 columns]\n",
      "error\n",
      "[[  3.11777046   4.07958868  21.47026025 ...,   5.41454087   5.26070965\n",
      "    0.53980594]\n",
      " [  3.70110379   3.49625534  20.88692691 ...,   4.83120754   5.84404299\n",
      "    0.04352739]\n",
      " [ 11.45110379   4.25374466  13.13692691 ...,   2.91879246  13.59404299\n",
      "    7.79352739]\n",
      " ..., \n",
      " [  0.83222954   8.02958868  25.42026025 ...,   9.36454087   1.31070965\n",
      "    4.48980594]\n",
      " [  6.21556288  13.41292201  30.80359358 ...,  14.7478742    4.07262368\n",
      "    9.87313928]\n",
      " [  5.35110379   1.84625534  19.23692691 ...,   3.18120754   7.49404299\n",
      "    1.69352739]]\n",
      "mean abs error\n",
      "7.17307083837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Documents/ProbabilisticProgrammingProject/venv/lib/python3.6/site-packages/ipykernel_launcher.py:43: RuntimeWarning: covariance is not positive-semidefinite.\n"
     ]
    }
   ],
   "source": [
    "n_test, d_test = x_test.shape\n",
    "y_n, y_d = y_train_raw.shape\n",
    "N, D = x_train.shape\n",
    "\n",
    "x_test_gp = tf.placeholder(tf.float32, [n_test, d_test])\n",
    "x_gp = tf.placeholder(tf.float32, [N, D])\n",
    "y_gp = tf.placeholder(tf.float32, [y_n, y_d])\n",
    "\n",
    "mu, var = tf.nn.moments(y_gp, 1)\n",
    "\n",
    "v_i = tf.eye(N) * var\n",
    "\n",
    "k = ed.rbf(x_gp, lengthscale=0.9996, variance=1.0) + v_i\n",
    "\n",
    "k_star = ed.rbf(x_test_gp, x_gp)\n",
    "\n",
    "k_star_star = ed.rbf(x_test_gp)\n",
    "\n",
    "k_inv = tf.matrix_inverse(k)\n",
    "\n",
    "mu_star = tf.matmul(tf.matmul(k_star, k_inv), y_gp)\n",
    "\n",
    "tmp1 = tf.matmul(k_star, k_inv)\n",
    "\n",
    "tmp2 = tf.matmul(tmp1, k_star, transpose_b=True)\n",
    "\n",
    "v_star = k_star_star - tmp2\n",
    "\n",
    "L = tf.cholesky(tf.abs(v_star))\n",
    "\n",
    "# p_y = ed.models.Normal(loc=mu_star, scale=v_star)\n",
    "m = mu_star.eval(session=tf.Session(), feed_dict={\n",
    "    x_gp: x_train.as_matrix(),\n",
    "    y_gp: y_train_raw.as_matrix(),\n",
    "    x_test_gp: x_test.as_matrix()\n",
    "})\n",
    "\n",
    "cov = v_star.eval(session=tf.Session(), feed_dict={\n",
    "    x_gp: x_train.as_matrix(),\n",
    "    y_gp: y_train_raw.as_matrix(),\n",
    "    x_test_gp: x_test.as_matrix()})\n",
    "\n",
    "expected = np.random.multivariate_normal(m.reshape((m.shape[0],)), cov)\n",
    "# p_y = ed.models.Normal(loc=tf.reshape(m, (m.shape[0],)), scale=cov)\n",
    "\n",
    "# expected = p_y.sample().eval(session=tf.Session(), feed_dict={\n",
    "#     x_gp: x_train.as_matrix(),\n",
    "#     y_gp: y_train_raw.as_matrix(),\n",
    "#     x_test_gp: x_test.as_matrix()\n",
    "# })\n",
    "\n",
    "print(\"expected.shape\", expected.shape)\n",
    "# expected = mu_star.eval(session=tf.Session(), feed_dict={\n",
    "#     x_gp: x_train.as_matrix(),\n",
    "#     y_gp: y_train_raw.as_matrix(),\n",
    "#     x_test_gp: x_test.as_matrix()\n",
    "# })\n",
    "\n",
    "print(\"prediction\")\n",
    "print(expected)\n",
    "print(\"actual\")\n",
    "print(y_test_raw)\n",
    "print(\"error\")\n",
    "err = y_test_raw.as_matrix() - expected\n",
    "print(np.abs(err))\n",
    "print(\"mean abs error\")\n",
    "print(np.abs(err).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_rbf(X, X2=None, lengthscale=1.0, variance=1.0): \n",
    "    X = tf.convert_to_tensor(X)\n",
    "    X = X / lengthscale\n",
    "    Xs = tf.reduce_sum(tf.square(X), 1)\n",
    "    if X2 is None:\n",
    "        X2 = X\n",
    "        X2s = Xs\n",
    "    else:\n",
    "        X2 = tf.convert_to_tensor(X2)\n",
    "        X2 = X2 / lengthscale\n",
    "        X2s = tf.reduce_sum(tf.square(X2), 1)\n",
    "\n",
    "    square = tf.reshape(Xs, [-1, 1]) + tf.reshape(X2s, [1, -1]) - 2 * tf.matmul(X, X2, transpose_b=True)\n",
    "    output = variance * tf.exp(-square / 2)\n",
    "    return output\n",
    "my_rbf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'scale'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ec4543bb3c96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m inf_gp_qf = ed.models.Normal(loc=tf.Variable(tf.random_normal([N])),\n\u001b[1;32m      4\u001b[0m             scale=tf.nn.softplus(tf.Variable(tf.random_normal([N]))))\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf_gp_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m inference_gp = ed.KLqp({inf_gp_y: inf_gp_qf}, data={inf_gp_x: x_train_standardized_harlem_to_bat_park.as_matrix(),\n\u001b[1;32m      7\u001b[0m                                     inf_gp_y: np.reshape(y_train_harlem_to_bat_park.as_matrix(), (y_train_harlem_to_bat_park.shape[0],))})\n",
      "\u001b[0;32m~/Documents/ProbabilisticProgrammingProject/venv/lib/python3.6/site-packages/edward/models/random_variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# to use _candidate's docstring, must write a new __init__ method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0m_RandomVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0m__init__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_candidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     _params = {'__doc__': _candidate.__doc__,\n",
      "\u001b[0;32m~/Documents/ProbabilisticProgrammingProject/venv/lib/python3.6/site-packages/edward/models/random_variable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'collections'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'scale'"
     ]
    }
   ],
   "source": [
    "gp = ed.models.MultivariateNormalTriL(scale=tf.zeros([N]), scale_tril=tf.cho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Key-value pair in data does not have same shape: (32,), (7,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-671347b698b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m             data={inf_gp_x: x_test_standardized_harlem_to_bat_park.as_matrix(),\n\u001b[1;32m      3\u001b[0m                   inf_gp_qf: np.reshape(y_test_harlem_to_bat_park.as_matrix(), (y_test_harlem_to_bat_park.shape[0]))},\n\u001b[0;32m----> 4\u001b[0;31m              output_key=inf_gp_qf)\n\u001b[0m",
      "\u001b[0;32m~/Documents/ProbabilisticProgrammingProject/venv/lib/python3.6/site-packages/edward/criticisms/evaluate.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(metrics, data, n_samples, output_key)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"metrics must have type str or list.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m   \u001b[0mcheck_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_samples must have type int.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ProbabilisticProgrammingProject/venv/lib/python3.6/site-packages/edward/util/random_variables.py\u001b[0m in \u001b[0;36mcheck_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m           raise TypeError(\"Key-value pair in data does not have same \"\n\u001b[0;32m---> 48\u001b[0;31m                           \"shape: {}, {}\".format(key.shape, np.shape(value)))\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Key-value pair in data does not have same shape: (32,), (7,)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ed.evaluate(\"mean_absolute_error\",\n",
    "            data={inf_gp_x: x_test_standardized_harlem_to_bat_park.as_matrix(),\n",
    "                  inf_gp_qf: np.reshape(y_test_harlem_to_bat_park.as_matrix(), (y_test_harlem_to_bat_park.shape[0]))},\n",
    "             output_key=inf_gp_qf)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
