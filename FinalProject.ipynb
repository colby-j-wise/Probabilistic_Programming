{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi Trips and Traffic\n",
    "\n",
    "Where most models use real-time data from users to predict arrival\n",
    "times, we believe they could be improved by including a predictive\n",
    "element. Our intent is to use the NYC Taxi and Limousine Commission's yellow and green cab data set to estimate density of pickup and dropoffs at any given place and time. We will then use the density as a proxy for traffic to estimate the time it takes to arrive at a destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import edward as ed\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Use the\n",
    "[2015 NYC Yellow Cab Dataset](http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml),\n",
    "which consists of pickup and dropoff coordinates for trips, along \n",
    "with metadata like cost, distance, and number of passengers. For the time being, we are only interested in trips that occurr entirely within the range from 1st street to 59th street, and 12th ave to 1st ave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>...</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>distance_between_service</th>\n",
       "      <th>time_between_service</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>imp_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-01 16:14:02</td>\n",
       "      <td>2015-10-01 16:14:17</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.969788</td>\n",
       "      <td>40.762821</td>\n",
       "      <td>-73.969765</td>\n",
       "      <td>40.762894</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.80</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-03-02 21:27:35</td>\n",
       "      <td>2015-03-02 21:37:26</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.006866</td>\n",
       "      <td>40.729382</td>\n",
       "      <td>-73.983521</td>\n",
       "      <td>40.746910</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.80</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-08-20 00:25:07</td>\n",
       "      <td>2015-08-20 00:25:30</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.005814</td>\n",
       "      <td>40.737202</td>\n",
       "      <td>-74.005829</td>\n",
       "      <td>40.737209</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-02-07 19:47:46</td>\n",
       "      <td>2015-02-07 19:55:55</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.995461</td>\n",
       "      <td>40.760078</td>\n",
       "      <td>-73.995087</td>\n",
       "      <td>40.762066</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.30</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-08-07 20:41:24</td>\n",
       "      <td>2015-08-07 21:16:03</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.992729</td>\n",
       "      <td>40.735725</td>\n",
       "      <td>-73.992523</td>\n",
       "      <td>40.735588</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.76</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_id     pickup_datetime    dropoff_datetime store_and_fwd_flag  \\\n",
       "0          1 2015-10-01 16:14:02 2015-10-01 16:14:17                  N   \n",
       "1          2 2015-03-02 21:27:35 2015-03-02 21:37:26                  N   \n",
       "2          1 2015-08-20 00:25:07 2015-08-20 00:25:30                  N   \n",
       "3          2 2015-02-07 19:47:46 2015-02-07 19:55:55                  N   \n",
       "4          2 2015-08-07 20:41:24 2015-08-07 21:16:03                  N   \n",
       "\n",
       "   rate_code  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0          1        -73.969788        40.762821         -73.969765   \n",
       "1          1        -74.006866        40.729382         -73.983521   \n",
       "2          1        -74.005814        40.737202         -74.005829   \n",
       "3          1        -73.995461        40.760078         -73.995087   \n",
       "4          1        -73.992729        40.735725         -73.992523   \n",
       "\n",
       "   dropoff_latitude  passenger_count      ...        mta_tax  tip_amount  \\\n",
       "0         40.762894                1      ...            0.5        0.00   \n",
       "1         40.746910                1      ...            0.5        0.00   \n",
       "2         40.737209                1      ...            0.5        0.00   \n",
       "3         40.762066                1      ...            0.5        0.00   \n",
       "4         40.735588                1      ...            0.5        5.46   \n",
       "\n",
       "   tolls_amount  ehail_fee  total_amount  payment_type  \\\n",
       "0           0.0        NaN         23.80             2   \n",
       "1           0.0        NaN         10.80             2   \n",
       "2           0.0        NaN          3.80             3   \n",
       "3           0.0        NaN          7.30             2   \n",
       "4           0.0        NaN         32.76             1   \n",
       "\n",
       "   distance_between_service  time_between_service  trip_type  imp_surcharge  \n",
       "0                       NaN                   NaN          1            0.3  \n",
       "1                       NaN                   NaN          1            0.3  \n",
       "2                       NaN                   NaN          1            0.3  \n",
       "3                       NaN                   NaN          1            0.3  \n",
       "4                       NaN                   NaN          1            0.3  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.set_seed(42)\n",
    "\n",
    "data = pd.read_csv('data/results-20171021-152500.csv',\n",
    "                   parse_dates=['pickup_datetime', 'dropoff_datetime'],\n",
    "                   date_parser=pd.to_datetime)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "A Gaussian process is a powerful object for modeling nonlinear\n",
    "relationships between pairs of random variables. It defines a distribution over\n",
    "(possibly nonlinear) functions, which can be applied for representing\n",
    "our uncertainty around the true functional relationship.\n",
    "Here we define a Gaussian process model for classification\n",
    "(Rasumussen & Williams, 2006).\n",
    "\n",
    "Formally, a distribution over functions $f:\\mathbb{R}^D\\to\\mathbb{R}$ can be specified\n",
    "by a Gaussian process\n",
    "$$\n",
    "\\begin{align*}\n",
    "  p(f)\n",
    "  &=\n",
    "  \\mathcal{GP}(f\\mid \\mathbf{0}, k(\\mathbf{x}, \\mathbf{x}^\\prime)),\n",
    "\\end{align*}\n",
    "$$\n",
    "whose mean function is the zero function, and whose covariance\n",
    "function is some kernel which describes dependence between\n",
    "any set of inputs to the function.\n",
    "\n",
    "Given a set of input-output pairs\n",
    "$\\{\\mathbf{x}_n\\in\\mathbb{R}^D,y_n\\in\\mathbb{R}\\}$,\n",
    "the likelihood can be written as a multivariate normal\n",
    "\n",
    "\\begin{align*}\n",
    "  p(\\mathbf{y})\n",
    "  &=\n",
    "  \\text{Normal}(\\mathbf{y} \\mid \\mathbf{0}, \\mathbf{K})\n",
    "\\end{align*}\n",
    "\n",
    "where $\\mathbf{K}$ is a covariance matrix given by evaluating\n",
    "$k(\\mathbf{x}_n, \\mathbf{x}_m)$ for each pair of inputs in the data\n",
    "set.\n",
    "\n",
    "The above applies directly for regression where $\\mathbb{y}$ is a\n",
    "real-valued response, but not for (binary) classification, where $\\mathbb{y}$\n",
    "is a label in $\\{0,1\\}$. To deal with classification, we interpret the\n",
    "response as latent variables which is squashed into $[0,1]$. We then\n",
    "draw from a Bernoulli to determine the label, with probability given\n",
    "by the squashed value.\n",
    "\n",
    "Define the likelihood of an observation $(\\mathbf{x}_n, y_n)$ as\n",
    "\n",
    "\\begin{align*}\n",
    "  p(y_n \\mid \\mathbf{z}, x_n)\n",
    "  &=\n",
    "  \\text{Bernoulli}(y_n \\mid \\text{logit}^{-1}(\\mathbf{x}_n^\\top \\mathbf{z})).\n",
    "\\end{align*}\n",
    "\n",
    "Define the prior to be a multivariate normal\n",
    "\n",
    "\\begin{align*}\n",
    "  p(\\mathbf{z})\n",
    "  &=\n",
    "  \\text{Normal}(\\mathbf{z} \\mid \\mathbf{0}, \\mathbf{K}),\n",
    "\\end{align*}\n",
    "\n",
    "with covariance matrix given as previously stated.\n",
    "\n",
    "Let's build the model in Edward. We use a radial basis function (RBF)\n",
    "kernel, also known as the squared exponential or exponentiated\n",
    "quadratic. It returns the kernel matrix evaluated over all pairs of\n",
    "data points; we then Cholesky decompose the matrix to parameterize the\n",
    "multivariate normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [N, D])\n",
    "f = MultivariateNormalTriL(loc=tf.zeros(N), scale_tril=tf.cholesky(rbf(X)))\n",
    "y = Bernoulli(logits=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define a placeholder `X`. During inference, we pass in\n",
    "the value for this placeholder according to data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Perform variational inference.\n",
    "Define the variational model to be a fully factorized normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qf = Normal(loc=tf.Variable(tf.random_normal([N])),\n",
    "            scale=tf.nn.softplus(tf.Variable(tf.random_normal([N]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run variational inference for `500` iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Elapsed: 9s | Loss: 82.755\n"
     ]
    }
   ],
   "source": [
    "inference = ed.KLqp({f: qf}, data={X: X_train, y: y_train})\n",
    "inference.run(n_iter=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case\n",
    "`KLqp` defaults to minimizing the\n",
    "$\\text{KL}(q\\|p)$ divergence measure using the reparameterization\n",
    "gradient.\n",
    "For more details on inference, see the [$\\text{KL}(q\\|p)$ tutorial](/tutorials/klqp).\n",
    "(This example happens to be slow because evaluating and inverting full\n",
    "covariances in Gaussian processes happens to be slow.)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
